# coding:utf-8
import numpy as np
import cv2 as cv
import cv2


# 自适应混合高斯模型的背景建模算法
def background_not_clear():
    cap = cv.VideoCapture('222.mp4')

    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3, 3))
    # fgbg = cv.createBackgroundSubtractorMOG2()
    fgbg = cv.createBackgroundSubtractorKNN()

    while (1):
        ret, frame = cap.read()
        fgmask = fgbg.apply(frame)
        fgmask = cv.morphologyEx(fgmask, cv.MORPH_OPEN, kernel)
        cv.imshow('frame', fgmask)
        if cv.waitKey(30) & 0xff == ord('q'):
            break

    cap.release()
    cv.destroyAllWindows()


##人体姿势评估
def body_reknow():
    # 加载模型
    net = cv2.dnn.readNetFromTensorflow('pose_estimation.pb')

    # 定义关键点的对应关系
    keypoints_mapping = {
        0: "Nose",
        1: "Neck",
        2: "RShoulder",
        3: "RElbow",
        4: "RWrist",
        5: "LShoulder",
        6: "LElbow",
        7: "LWrist",
        8: "RHip",
        9: "RKnee",
        10: "RAnkle",
        11: "LHip",
        12: "LKnee",
        13: "LAnkle",
        14: "REye",
        15: "LEye",
        16: "REar",
        17: "LEar"
    }

    # 定义姿势评估函数
    def pose_estimate(frame):
        # 将图像转换为blob格式
        blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224), (0, 0, 0), swapRB=False, crop=False)

        # 将blob输入到网络中进行预测
        net.setInput(blob)
        output = net.forward()

        # 提取关键点
        keypoints = output[0, :, :, :]

        # 获取关键点的位置信息
        H = frame.shape[0]
        W = frame.shape[1]
        keypoints_list = np.zeros((len(keypoints_mapping), 2), dtype=np.int32)
        for i, keypoint in enumerate(keypoints_mapping.keys()):
            x = int(keypoints[0, i, 0] * W)
            y = int(keypoints[0, i, 1] * H)
            keypoints_list[i] = [x, y]

        # 绘制关键点
        for keypoint in keypoints_list:
            cv2.circle(frame, (keypoint[0], keypoint[1]), 3, (0, 255, 0), -1)

        # 根据关键点位置评估姿势
        # TODO: 实现自己的姿势评估逻辑

        return frame

    # 打开摄像头并处理每一帧图像
    cap = cv2.VideoCapture(0)
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frame = pose_estimate(frame)
        cv2.imshow('frame', frame)

        if cv2.waitKey(1) == ord('q'):
            break
    cap.release()
    cv2.destroyAllWindows()


def fushipengzhang():  # 先腐蚀后膨胀去除噪点
    # 读取图像
    cap = cv.VideoCapture('222.mp4')
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # 转换为灰度图像
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        #    ret, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY) 二值化图像
        ret, thresh = cv2.threshold(gray, 0, 155, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        # 定义核函数
        kernel = np.ones((3, 3), np.uint8)

        contour_img = np.zeros(thresh.shape[:2], dtype=np.uint8)

        # 二进制轮廊查找
        #  image：输入二进制图像，必须是单通道（灰度）图像。
        # mode：轮廓检索模式，表示轮廓的层级结构。有以下四种取值：
        # cv2.RETR_EXTERNAL：只检测最外层的轮廓；
        # cv2.RETR_LIST：检测所有轮廓，但不建立轮廓层级关系；
        # cv2.RETR_CCOMP：检测所有轮廓，建立两层轮廓层级关系；
        # cv2.RETR_TREE：检测所有轮廓，建立完整的轮廓层级树。
        # method：轮廓逼近方法，表示轮廓的连续性。有以下两种取值：
        # cv2.CHAIN_APPROX_NONE：保存所有轮廓点；
        # cv2.CHAIN_APPROX_SIMPLE：只保存轮廓的拐点处点，把所有拐点处的点压缩成一个点。
        # contours：可选参数，表示输出的轮廓，是一个 Python 列表，其中每个元素是一个轮廓的点集。
        # hierarchy：可选参数，表示输出的轮廓层级关系，是一个包含每个轮廓层级信息的 Numpy 数组。
        # offset：可选参数，表示轮廓点集坐标偏移量。
        contours, hierarchy = cv2.findContours(contour_img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)
        # 腐蚀操作
        erosion = cv2.erode(thresh, kernel=kernel, iterations=1)
        # 膨胀操作
        contour_img = cv2.dilate(erosion, kernel=kernel, iterations=1)
        # 描绘轮廊
        cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 1)
        # 阈值处理，二值化

        # 腐蚀操作
        #  erosion = cv2.erode(thresh, kernel, iterations=20)
        # 膨胀操作
        # dilation = cv2.dilate(erosion, kernel, iterations=15)

        # 找出轮廓
        contours, hierarchy = cv2.findContours(contour_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # 获取目标框的坐标和宽高
        x, y, w, h = cv2.boundingRect(contours[0])

        # 绘制目标框
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 2)
        cv2.rectangle(contour_img, (x, y), (x + w, y + h), (51, 255, 51), 3)
        # 显示图像
        cv2.imshow('image', frame)
        cv2.imshow("seconds picture", contour_img)

        if cv.waitKey(30) & 0xff == ord('q'):
            break
    cap.release()
    cv.destroyAllWindows()


# background_not_clear()
fushipengzhang()


